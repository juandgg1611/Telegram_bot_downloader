"""
M√≥dulo para descargar contenido de Pinterest.
Soporta: im√°genes (JPG, PNG, WebP), videos, Pins m√∫ltiples (carruseles).
"""
import os
import re
import logging
import time
import requests
import json
from typing import Optional, Tuple, Dict, Any, List
from urllib.parse import urlparse, parse_qs, unquote
from dataclasses import dataclass

# yt-dlp puede servir como respaldo para algunos recursos
import yt_dlp
from ..config import DOWNLOAD_DIR, MAX_FILE_SIZE  

logger = logging.getLogger(__name__)

# ============================================================================
# CLASES DE DATOS
# ============================================================================
@dataclass
class PinterestContentInfo:
    """Informaci√≥n estructurada del contenido de Pinterest."""
    id: str
    content_type: str  
    title: str
    description: str
    uploader: str  
    source_url: Optional[str]  
    pinterest_url: str  
    download_urls: List[str]  
    width: int
    height: int
    duration: Optional[int] = None  
    is_video: bool = False

# ============================================================================
# CLASE PRINCIPAL
# ============================================================================
class PinterestDownloader:
    """
    Descargador de contenido de Pinterest.
    Estrategia:
    1. Intentar obtener metadatos y URLs directas v√≠a la API oficial (si hay token).
    2. Recurrir a web scraping y b√∫squeda de metadatos Open Graph como respaldo.
    """
    HEADERS = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'es-ES,es;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate',
        'DNT': '1',
        'Connection': 'keep-alive',
    }

    # Patrones para identificar URLs de Pinterest
    URL_PATTERNS = {
        'pin': r'https?://(?:www\.)?pinterest\.(?:com|fr|de|co\.uk|ru|etc)/pin/(\d+)',
        'image': r'https?://(?:www\.)?pinterest\.(?:com|fr|de|co\.uk|ru|etc)/[^/]+/[^/]+/',
        'pin_it': r'https?://pin\.it/[\w]+',  
        'pin_it_with_params': r'https?://pin\.it/[\w]+\?.*',  
    }

    def __init__(self, api_token: Optional[str] = None):
        """
        Inicializa el descargador.
        :param api_token: Token OAuth de la API de Pinterest (opcional, pero recomendado).
        """
        self.api_token = api_token
        self.session = requests.Session()
        self.session.headers.update(self.HEADERS)

    # ------------------------------------------------------------------------
    # M√âTODOS DE DETECCI√ìN Y EXTRACCI√ìN DE INFORMACI√ìN
    # ------------------------------------------------------------------------
    @classmethod
    def is_pinterest_url(cls, url: str) -> bool:
        """Verifica si una URL es de Pinterest."""
        return any(re.match(pattern, url) for pattern in cls.URL_PATTERNS.values())

    def extract_pin_id(self, url: str) -> Optional[str]:
        """Extrae el ID del Pin de la URL."""
        match = re.search(self.URL_PATTERNS['pin'], url)
        return match.group(1) if match else None

    def get_content_info(self, url: str) -> PinterestContentInfo:
        """
        Obtiene metadatos del Pin. Combina API y scraping.
        """
        pin_id = self.extract_pin_id(url)
        content_info = None

        # 1. Intento principal: Usar la API oficial de Pinterest (si tenemos token)
        if self.api_token and pin_id:
            content_info = self._get_info_via_api(pin_id)

        # 2. Intento de respaldo: Scraping de la p√°gina web
        if not content_info:
            content_info = self._get_info_via_scraping(url)

        # Si todo falla, devolver informaci√≥n b√°sica
        if not content_info:
            content_info = PinterestContentInfo(
                id=pin_id or f"pin_{int(time.time())}",
                content_type='unknown',
                title='Pin de Pinterest',
                description='',
                uploader='',
                source_url=None,
                pinterest_url=url,
                download_urls=[],
                width=0,
                height=0
            )

        return content_info

    def _get_info_via_api(self, pin_id: str) -> Optional[PinterestContentInfo]:
        """Intenta obtener informaci√≥n usando la API oficial v5."""
        if not self.api_token:
            return None

        try:
            url = f"https://api.pinterest.com/v5/pins/{pin_id}"
            headers = {
                'Authorization': f'Bearer {self.api_token}',
                'Content-Type': 'application/json'
            }
            response = self.session.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            data = response.json()

            # Extraer URLs de medios. La estructura puede variar.
            download_urls = []
            media_type = 'image'

            # Para im√°genes
            if 'images' in data and 'orig' in data['images']:
                download_urls.append(data['images']['orig']['url'])
                # Tambi√©n puedes a√±adir otros tama√±os: data['images'].get('736x', {}).get('url')
            # Para videos
            if 'videos' in data and 'video_list' in data['videos']:
                # Buscar la mejor calidad disponible
                video_data = data['videos']['video_list']
                if 'V_720P' in video_data:
                    download_urls.append(video_data['V_720P']['url'])
                elif 'V_HLSV3' in video_data:
                    download_urls.append(video_data['V_HLSV3']['url'])
                media_type = 'video'

            return PinterestContentInfo(
                id=data.get('id', pin_id),
                content_type=media_type,
                title=data.get('title', data.get('alt_text', '')),
                description=data.get('description', data.get('alt_text', '')),
                uploader=data.get('board_owner', {}).get('username', ''),
                source_url=data.get('link', None),
                pinterest_url=data.get('url', f'https://pinterest.com/pin/{pin_id}'),
                download_urls=download_urls,
                width=data.get('images', {}).get('orig', {}).get('width', 0),
                height=data.get('images', {}).get('orig', {}).get('height', 0),
                is_video=(media_type == 'video')
            )

        except Exception as e:
            logger.debug(f"API oficial fall√≥ para {pin_id}: {e}")
            return None

    def _get_info_via_scraping(self, url: str) -> Optional[PinterestContentInfo]:
        """
        M√©todo de respaldo: Extrae informaci√≥n analizando el HTML de la p√°gina.
        Busca metadatos Open Graph y enlaces a recursos.
        """
        try:
            # Usar headers m√°s realistas
            headers = {
                **self.HEADERS,
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9',
                'Cache-Control': 'no-cache',
            }
            
            response = self.session.get(url, headers=headers, timeout=15)
            response.raise_for_status()
            html = response.text
            
            print(f"üîç HTML obtenido ({len(html)} bytes)")  # Debug
            
            # 1. BUSCAR VIDEO primero (m√°s valioso)
            download_urls = []
            media_type = 'image'
            
            # Patrones para encontrar videos
            video_patterns = [
                r'"contentUrl":"([^"]+\.mp4[^"]*)"',
                r'"videoUrl":"([^"]+)"',
                r'property="og:video" content="([^"]+)"',
                r'<meta[^>]*property="og:video:url"[^>]*content="([^"]+)"',
                r'src="([^"]+\.mp4)"',
            ]
            
            for pattern in video_patterns:
                matches = re.findall(pattern, html, re.IGNORECASE)
                for match in matches:
                    if match and 'http' in match:
                        video_url = match.replace('\\/', '/')
                        if video_url not in download_urls:
                            download_urls.append(video_url)
                            media_type = 'video'
                            print(f"‚úÖ Video encontrado: {video_url[:80]}...")
                            break
                if download_urls:
                    break
            
            # 2. Si no hay video, buscar IMAGEN
            if not download_urls:
                image_patterns = [
                    r'property="og:image" content="([^"]+)"',
                    r'<meta[^>]*property="og:image:url"[^>]*content="([^"]+)"',
                    r'"image":"([^"]+)"',
                    r'src="([^"]+\.(?:jpg|jpeg|png|webp|gif))"[^>]*class="[^"]*hcl[^"]*"',
                    r'data-test-id="pin-closeup-image" src="([^"]+)"',
                ]
                
                for pattern in image_patterns:
                    matches = re.findall(pattern, html, re.IGNORECASE)
                    for match in matches:
                        if match and 'http' in match:
                            img_url = match.replace('\\/', '/')
                            if img_url not in download_urls:
                                download_urls.append(img_url)
                                print(f"‚úÖ Imagen encontrada: {img_url[:80]}...")
                                break
                    if download_urls:
                        break
            
            # 3. Extraer t√≠tulo y descripci√≥n
            title = self._extract_og_tag(html, 'og:title') or 'Pin de Pinterest'
            description = self._extract_og_tag(html, 'og:description') or ''
            
            # Extraer usuario si es posible
            uploader = ''
            user_patterns = [
                r'"creator":"([^"]+)"',
                r'"username":"([^"]+)"',
                r'@([\w\-_]+)',
            ]
            
            for pattern in user_patterns:
                match = re.search(pattern, html)
                if match:
                    uploader = match.group(1)
                    break
            
            print(f"üìä Info extra√≠da: {title[:50]}... | URLs: {len(download_urls)}")
            
            if download_urls:
                return PinterestContentInfo(
                    id=self.extract_pin_id(url) or f"scraped_{int(time.time())}",
                    content_type=media_type,
                    title=title[:200],
                    description=description[:500],
                    uploader=uploader,
                    source_url=self._extract_og_tag(html, 'og:url'),
                    pinterest_url=url,
                    download_urls=download_urls,
                    width=0,
                    height=0,
                    is_video=(media_type == 'video')
                )
            
            return None
            
        except Exception as e:
            print(f"‚ùå Error en scraping: {e}")  # Debug
            import traceback
            traceback.print_exc()
            return None

    def _extract_og_tag(self, html: str, property_name: str) -> Optional[str]:
        """Extrae el contenido de una metaetiqueta Open Graph."""
        pattern = f'<meta property="{property_name}" content="([^"]*)"'
        match = re.search(pattern, html)
        return match.group(1) if match else None

    # ------------------------------------------------------------------------
    # M√âTODO PRINCIPAL DE DESCARGA
    # ------------------------------------------------------------------------
    def download(self, url: str) -> Tuple[str, Dict[str, Any]]:
        """
        Descarga el contenido de un Pin de Pinterest.
        :return: (ruta_al_archivo, informaci√≥n_del_contenido)
        """
        if not self.is_pinterest_url(url):
            raise ValueError("URL de Pinterest no v√°lida.")

        content_info = self.get_content_info(url)

        if not content_info.download_urls:
            raise ValueError("No se pudieron encontrar enlaces de descarga para este Pin.")

        # Descargar el primer recurso disponible (podr√≠as extenderlo para carruseles)
        download_url = content_info.download_urls[0]
        filepath = self._download_resource(download_url, content_info)

        # Verificar tama√±o del archivo
        if os.path.getsize(filepath) > MAX_FILE_SIZE:
            os.remove(filepath)
            raise ValueError(f"Archivo demasiado grande (> {MAX_FILE_SIZE} bytes).")

        # Preparar informaci√≥n de resultado
        result_info = {
            'id': content_info.id,
            'title': content_info.title[:100],
            'uploader': content_info.uploader,
            'content_type': content_info.content_type,
            'is_video': content_info.is_video,
            'pinterest_url': content_info.pinterest_url,
            'source_url': content_info.source_url,
            'file_size': os.path.getsize(filepath),
            'file_path': filepath
        }

        logger.info(f"‚úÖ Descargado: {filepath}")
        return filepath, result_info

    def _download_resource(self, url: str, info: PinterestContentInfo) -> str:
        """
        Descarga un recurso (imagen o video) desde una URL directa.
        """
        # Determinar extensi√≥n del archivo
        parsed_url = urlparse(url)
        # Extraer extensi√≥n del path o de par√°metros
        path_ext = os.path.splitext(parsed_url.path)[1]
        if path_ext:
            # Limpiar la extensi√≥n (p.ej., .jpg?1234 -> .jpg)
            ext = path_ext.split('?')[0].lower()
        else:
            # Asignar extensi√≥n por defecto basada en el tipo
            ext = '.mp4' if info.is_video else '.jpg'

        # Crear nombre de archivo seguro
        safe_title = re.sub(r'[^\w\-_\. ]', '_', info.title[:50])
        filename = f"pinterest_{info.id}_{safe_title}{ext}"
        filepath = os.path.join(DOWNLOAD_DIR, filename)

        # Descargar con requests
        response = self.session.get(url, stream=True, timeout=30)
        response.raise_for_status()

        with open(filepath, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)

        return filepath

    # ------------------------------------------------------------------------
    # M√âTODOS AUXILIARES
    # ------------------------------------------------------------------------
    def cleanup(self, filepath: str):
        """Elimina un archivo descargado."""
        try:
            if os.path.exists(filepath):
                os.remove(filepath)
        except Exception as e:
            logger.warning(f"No se pudo eliminar {filepath}: {e}")